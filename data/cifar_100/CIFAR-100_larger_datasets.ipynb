{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dir(data_dir):\n",
    "    clients = []\n",
    "    cluster_ids = {}\n",
    "    groups = []\n",
    "    data = defaultdict(lambda : None)\n",
    "\n",
    "    files = os.listdir(data_dir)\n",
    "    files = [f for f in files if f.endswith('.json')]\n",
    "    for f in files:\n",
    "        file_path = os.path.join(data_dir,f)\n",
    "        with open(file_path, 'r') as inf:\n",
    "            cdata = json.load(inf)\n",
    "        clients.extend(cdata['users'])\n",
    "        if 'cluster_ids' in cdata:\n",
    "            for idx, u in enumerate(cdata['users']):\n",
    "                cluster_ids[u] = cdata['cluster_ids'][idx]\n",
    "        if 'hierarchies' in cdata:\n",
    "            groups.extend(cdata['hierarchies'])\n",
    "        data.update(cdata['user_data'])\n",
    "\n",
    "    clients = list(sorted(data.keys()))\n",
    "    # If there are no cluser_ids in the data, assign 0 for each user\n",
    "    cluster_ids = [cluster_ids[c] if c in cluster_ids else 0 for c in clients]\n",
    "    return clients, cluster_ids, groups, data\n",
    "\n",
    "def read_data(train_data_dir, test_data_dir):\n",
    "    '''parses data in given train and test data directories\n",
    "\n",
    "    assumes:\n",
    "    - the data in the input directories are .json files with\n",
    "        keys 'users', 'user_data' and 'cluster_ids'\n",
    "    - the set of train set users is the same as the set of test set users\n",
    "\n",
    "    Returns:\n",
    "        clients: list of client ids\n",
    "        groups: list of group ids; empty list if none found\n",
    "        train_data: dictionary of train data\n",
    "        test_data: dictionary of test data\n",
    "    '''\n",
    "    train_clients, train_cluster_ids, train_groups, train_data = read_dir(train_data_dir)\n",
    "    test_clients, test_cluster_ids, test_groups, test_data = read_dir(test_data_dir)\n",
    "\n",
    "    assert train_clients == test_clients\n",
    "    assert train_groups == test_groups\n",
    "    assert train_cluster_ids == test_cluster_ids\n",
    "\n",
    "    # Todo return groups if required\n",
    "    return train_clients, train_cluster_ids, train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../../.././data/cifar100/regular/'\n",
    "train_clients, train_cluster_ids, train_data, test_data = read_data(f'{data_dir}train/', f'{data_dir}test/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_cluster_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_data = {}\n",
    "new_test_data = {}\n",
    "new_cluster_ids = {}\n",
    "\n",
    "clusters = np.arange(20)\n",
    "\n",
    "for cluster_id in clusters:\n",
    "    client_ids = list(np.array(train_clients)[np.argwhere(np.array(train_cluster_ids) == cluster_id)].flatten())\n",
    "    while len(client_ids) > 1:\n",
    "        new_train_data[client_ids[0]] = {'x': train_data[client_ids[0]]['x'] + train_data[client_ids[-1]]['x'],\n",
    "                                         'y': train_data[client_ids[0]]['y'] + train_data[client_ids[-1]]['y']}\n",
    "        new_test_data[client_ids[0]] = {'x': test_data[client_ids[0]]['x'] + test_data[client_ids[-1]]['x'],\n",
    "                                         'y': test_data[client_ids[0]]['y'] + test_data[client_ids[-1]]['y']}\n",
    "        new_cluster_ids[client_ids[0]] = int(cluster_id)\n",
    "        del client_ids[0]\n",
    "        del client_ids[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 18, 18, 18, 18, 18, 18, 18, 18, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_cluster_ids.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_output = {\n",
    "    'user_data': new_train_data,\n",
    "    'cluster_ids': list(new_cluster_ids.values()),\n",
    "    'users': list(new_train_data.keys())\n",
    "}\n",
    "test_output = {\n",
    "    'user_data': new_test_data,\n",
    "    'cluster_ids': list(new_cluster_ids.values()),\n",
    "    'users': list(new_train_data.keys())\n",
    "}\n",
    "\n",
    "with open('../../.././data/cifar100/fewer_clients_more_data/train/data.json', 'w') as file: \n",
    "    json.dump(train_output, file)\n",
    "with open('../../.././data/cifar100/fewer_clients_more_data/test/data.json', 'w') as file: \n",
    "    json.dump(test_output, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
