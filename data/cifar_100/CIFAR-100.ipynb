{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_federated as tff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from functools import partial\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow_federated\n",
      "  Downloading tensorflow_federated-0.17.0-py2.py3-none-any.whl (517 kB)\n",
      "\u001b[K     |████████████████████████████████| 517 kB 3.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-addons~=0.11.1\n",
      "  Downloading tensorflow_addons-0.11.2-cp36-cp36m-manylinux2010_x86_64.whl (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 11.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting grpcio~=1.29.0\n",
      "  Downloading grpcio-1.29.0-cp36-cp36m-manylinux2010_x86_64.whl (3.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.0 MB 15.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-model-optimization~=0.4.0\n",
      "  Downloading tensorflow_model_optimization-0.4.1-py2.py3-none-any.whl (172 kB)\n",
      "\u001b[K     |████████████████████████████████| 172 kB 30.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting dm-tree~=0.1.1\n",
      "  Downloading dm_tree-0.1.5-cp36-cp36m-manylinux1_x86_64.whl (294 kB)\n",
      "\u001b[K     |████████████████████████████████| 294 kB 30.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_federated) (2.10.0)\n",
      "Collecting tensorflow~=2.3.0\n",
      "  Downloading tensorflow-2.3.1-cp36-cp36m-manylinux2010_x86_64.whl (320.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 320.4 MB 79 kB/s  eta 0:00:012    |█▍                              | 13.6 MB 32.5 MB/s eta 0:00:10     |██████▍                         | 64.3 MB 8.8 MB/s eta 0:00:30     |███████▏                        | 71.6 MB 10.4 MB/s eta 0:00:24     |█████████████                   | 130.0 MB 10.4 MB/s eta 0:00:19     |██████████████▏                 | 142.0 MB 11.8 MB/s eta 0:00:16     |██████████████████████████████▍ | 304.1 MB 14.0 MB/s eta 0:00:02\n",
      "\u001b[?25hCollecting cachetools~=3.1.1\n",
      "  Downloading cachetools-3.1.1-py2.py3-none-any.whl (11 kB)\n",
      "Collecting retrying~=1.3.3\n",
      "  Downloading retrying-1.3.3.tar.gz (10 kB)\n",
      "Collecting portpicker~=1.3.1\n",
      "  Downloading portpicker-1.3.1.tar.gz (18 kB)\n",
      "Collecting semantic-version~=2.8.5\n",
      "  Downloading semantic_version-2.8.5-py2.py3-none-any.whl (15 kB)\n",
      "Collecting tensorflow-privacy~=0.5.0\n",
      "  Downloading tensorflow_privacy-0.5.1-py3-none-any.whl (149 kB)\n",
      "\u001b[K     |████████████████████████████████| 149 kB 14.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting numpy~=1.18.4\n",
      "  Downloading numpy-1.18.5-cp36-cp36m-manylinux1_x86_64.whl (20.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 20.1 MB 10.6 MB/s eta 0:00:01   |                                | 51 kB 15.0 MB/s eta 0:00:02     |███████████████████▉            | 12.5 MB 10.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting attrs~=19.3.0\n",
      "  Downloading attrs-19.3.0-py2.py3-none-any.whl (39 kB)\n",
      "Collecting absl-py~=0.9.0\n",
      "  Downloading absl-py-0.9.0.tar.gz (104 kB)\n",
      "\u001b[K     |████████████████████████████████| 104 kB 9.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting typeguard>=2.7\n",
      "  Downloading typeguard-2.10.0-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.6/dist-packages (from grpcio~=1.29.0->tensorflow_federated) (1.15.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.3.0->tensorflow_federated) (0.2.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.3.0->tensorflow_federated) (3.13.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.3.0->tensorflow_federated) (3.3.0)\n",
      "Collecting tensorboard<3,>=2.3.0\n",
      "  Downloading tensorboard-2.4.0-py3-none-any.whl (10.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 10.6 MB 9.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting gast==0.3.3\n",
      "  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.3.0->tensorflow_federated) (0.35.1)\n",
      "Collecting tensorflow-estimator<2.4.0,>=2.3.0\n",
      "  Downloading tensorflow_estimator-2.3.0-py2.py3-none-any.whl (459 kB)\n",
      "\u001b[K     |████████████████████████████████| 459 kB 16.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.3.0->tensorflow_federated) (1.12.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.3.0->tensorflow_federated) (1.1.0)\n",
      "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.3.0->tensorflow_federated) (1.1.2)\n",
      "Collecting astunparse==1.6.3\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: scipy>=0.17 in /usr/local/lib/python3.6/dist-packages (from tensorflow-privacy~=0.5.0->tensorflow_federated) (1.4.1)\n",
      "Collecting mpmath\n",
      "  Downloading mpmath-1.1.0.tar.gz (512 kB)\n",
      "\u001b[K     |████████████████████████████████| 512 kB 16.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.9.2->tensorflow~=2.3.0->tensorflow_federated) (50.3.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow~=2.3.0->tensorflow_federated) (0.4.2)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.7.0-py3-none-any.whl (779 kB)\n",
      "\u001b[K     |████████████████████████████████| 779 kB 17.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow~=2.3.0->tensorflow_federated) (2.24.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow~=2.3.0->tensorflow_federated) (1.0.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow~=2.3.0->tensorflow_federated) (1.23.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow~=2.3.0->tensorflow_federated) (3.3.3)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow~=2.3.0->tensorflow_federated) (1.3.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow~=2.3.0->tensorflow_federated) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow~=2.3.0->tensorflow_federated) (1.22)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow~=2.3.0->tensorflow_federated) (2.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow~=2.3.0->tensorflow_federated) (2018.1.18)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.5\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow~=2.3.0->tensorflow_federated) (4.6)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow~=2.3.0->tensorflow_federated) (0.2.8)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow~=2.3.0->tensorflow_federated) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow~=2.3.0->tensorflow_federated) (3.1.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.5\"->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow~=2.3.0->tensorflow_federated) (0.4.8)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow~=2.3.0->tensorflow_federated) (3.4.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building wheels for collected packages: retrying, portpicker, absl-py, mpmath\n",
      "  Building wheel for retrying (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for retrying: filename=retrying-1.3.3-py3-none-any.whl size=11429 sha256=f9fa8e425fcfbfd73b792cd30db7b38e29af16fae946da67f81ec364a3576e8c\n",
      "  Stored in directory: /root/.cache/pip/wheels/ac/cb/8a/b27bf6323e2f4c462dcbf77d70b7c5e7868a7fbe12871770cf\n",
      "  Building wheel for portpicker (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for portpicker: filename=portpicker-1.3.1-py3-none-any.whl size=13664 sha256=9f9394dfca8a7ec5bd95b7e1f75e785f1457e34f00954128832a06db202636c6\n",
      "  Stored in directory: /root/.cache/pip/wheels/53/f1/26/e6fccc50aa37b340f1b9cc508827ef70b1a2767885f37539ca\n",
      "  Building wheel for absl-py (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for absl-py: filename=absl_py-0.9.0-py3-none-any.whl size=121932 sha256=4ef93d16976e9a2b65b8600c7916ec9b0de6ee5f2d6837b3171d28a482b02051\n",
      "  Stored in directory: /root/.cache/pip/wheels/c3/af/84/3962a6af7b4ab336e951b7877dcfb758cf94548bb1771e0679\n",
      "  Building wheel for mpmath (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for mpmath: filename=mpmath-1.1.0-py3-none-any.whl size=532239 sha256=9f6845e3f586af51af35adf61a3efea5610aee8de9f66965abb675d790202059\n",
      "  Stored in directory: /root/.cache/pip/wheels/e8/38/69/aa17553ad31f09ff5fa44c8a1a6c5b47e7c9261e9c7c16b9fb\n",
      "Successfully built retrying portpicker absl-py mpmath\n",
      "Installing collected packages: typeguard, tensorflow-addons, grpcio, numpy, dm-tree, tensorflow-model-optimization, tensorboard-plugin-wit, absl-py, tensorboard, gast, tensorflow-estimator, astunparse, tensorflow, cachetools, retrying, portpicker, semantic-version, mpmath, tensorflow-privacy, attrs, tensorflow-federated\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.33.2\n",
      "    Uninstalling grpcio-1.33.2:\n",
      "      Successfully uninstalled grpcio-1.33.2\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.16.4\n",
      "    Uninstalling numpy-1.16.4:\n",
      "      Successfully uninstalled numpy-1.16.4\n",
      "  Attempting uninstall: absl-py\n",
      "    Found existing installation: absl-py 0.11.0\n",
      "    Uninstalling absl-py-0.11.0:\n",
      "      Successfully uninstalled absl-py-0.11.0\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 1.13.1\n",
      "    Uninstalling tensorboard-1.13.1:\n",
      "      Successfully uninstalled tensorboard-1.13.1\n",
      "  Attempting uninstall: gast\n",
      "    Found existing installation: gast 0.4.0\n",
      "    Uninstalling gast-0.4.0:\n",
      "      Successfully uninstalled gast-0.4.0\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 1.13.0\n",
      "    Uninstalling tensorflow-estimator-1.13.0:\n",
      "      Successfully uninstalled tensorflow-estimator-1.13.0\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 1.13.1\n",
      "    Uninstalling tensorflow-1.13.1:\n",
      "      Successfully uninstalled tensorflow-1.13.1\n",
      "  Attempting uninstall: cachetools\n",
      "    Found existing installation: cachetools 4.1.1\n",
      "    Uninstalling cachetools-4.1.1:\n",
      "      Successfully uninstalled cachetools-4.1.1\n",
      "  Attempting uninstall: attrs\n",
      "    Found existing installation: attrs 19.1.0\n",
      "    Uninstalling attrs-19.1.0:\n",
      "      Successfully uninstalled attrs-19.1.0\n",
      "Successfully installed absl-py-0.9.0 astunparse-1.6.3 attrs-19.3.0 cachetools-3.1.1 dm-tree-0.1.5 gast-0.3.3 grpcio-1.29.0 mpmath-1.1.0 numpy-1.18.5 portpicker-1.3.1 retrying-1.3.3 semantic-version-2.8.5 tensorboard-2.4.0 tensorboard-plugin-wit-1.7.0 tensorflow-2.3.1 tensorflow-addons-0.11.2 tensorflow-estimator-2.3.0 tensorflow-federated-0.17.0 tensorflow-model-optimization-0.4.1 tensorflow-privacy-0.5.1 typeguard-2.10.0\n",
      "\u001b[33mWARNING: You are using pip version 20.2; however, version 20.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow_federated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: tensorflow-federated 0.17.0\n",
      "Uninstalling tensorflow-federated-0.17.0:\n",
      "  Successfully uninstalled tensorflow-federated-0.17.0\n",
      "Found existing installation: tensorflow-privacy 0.5.1\n",
      "Uninstalling tensorflow-privacy-0.5.1:\n",
      "  Successfully uninstalled tensorflow-privacy-0.5.1\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y tensorflow-federated\n",
    "!pip uninstall -y tensorflow-privacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: tensorflow-federated 0.17.0\n",
      "Uninstalling tensorflow-federated-0.17.0:\n",
      "  Would remove:\n",
      "    /usr/local/lib/python3.6/dist-packages/tensorflow_federated-0.17.0.dist-info/*\n",
      "    /usr/local/lib/python3.6/dist-packages/tensorflow_federated/*\n",
      "Proceed (y/n)? ^C\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\n",
      "Found existing installation: tensorflow-privacy 0.5.1\n",
      "Uninstalling tensorflow-privacy-0.5.1:\n",
      "  Would remove:\n",
      "    /usr/local/lib/python3.6/dist-packages/tensorflow_privacy-0.5.1.dist-info/*\n",
      "    /usr/local/lib/python3.6/dist-packages/tensorflow_privacy/*\n",
      "Proceed (y/n)? ^C\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\n",
      "Collecting grpcio==1.33.2\n",
      "  Using cached grpcio-1.33.2-cp36-cp36m-manylinux2014_x86_64.whl (3.8 MB)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5.2 in /usr/local/lib/python3.6/dist-packages (from grpcio==1.33.2) (1.15.0)\n",
      "Installing collected packages: grpcio\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.29.0\n",
      "    Uninstalling grpcio-1.29.0:\n",
      "      Successfully uninstalled grpcio-1.29.0\n",
      "\u001b[31mERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n",
      "\n",
      "We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n",
      "\n",
      "tensorflow-federated 0.17.0 requires grpcio~=1.29.0, but you'll have grpcio 1.33.2 which is incompatible.\u001b[0m\n",
      "Successfully installed grpcio-1.33.2\n",
      "\u001b[33mWARNING: You are using pip version 20.2; however, version 20.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting numpy==1.16.4\n",
      "  Using cached numpy-1.16.4-cp36-cp36m-manylinux1_x86_64.whl (17.3 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.18.5\n",
      "    Uninstalling numpy-1.18.5:\n",
      "      Successfully uninstalled numpy-1.18.5\n",
      "\u001b[31mERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n",
      "\n",
      "We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n",
      "\n",
      "tensorflow-federated 0.17.0 requires grpcio~=1.29.0, but you'll have grpcio 1.33.2 which is incompatible.\n",
      "tensorflow-federated 0.17.0 requires numpy~=1.18.4, but you'll have numpy 1.16.4 which is incompatible.\u001b[0m\n",
      "Successfully installed numpy-1.16.4\n",
      "\u001b[33mWARNING: You are using pip version 20.2; however, version 20.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting absl-py==0.11.0\n",
      "  Using cached absl_py-0.11.0-py3-none-any.whl (127 kB)\n",
      "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from absl-py==0.11.0) (1.15.0)\n",
      "Installing collected packages: absl-py\n",
      "  Attempting uninstall: absl-py\n",
      "    Found existing installation: absl-py 0.9.0\n",
      "    Uninstalling absl-py-0.9.0:\n",
      "      Successfully uninstalled absl-py-0.9.0\n",
      "\u001b[31mERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n",
      "\n",
      "We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n",
      "\n",
      "tensorflow-federated 0.17.0 requires absl-py~=0.9.0, but you'll have absl-py 0.11.0 which is incompatible.\n",
      "tensorflow-federated 0.17.0 requires grpcio~=1.29.0, but you'll have grpcio 1.33.2 which is incompatible.\n",
      "tensorflow-federated 0.17.0 requires numpy~=1.18.4, but you'll have numpy 1.16.4 which is incompatible.\u001b[0m\n",
      "Successfully installed absl-py-0.11.0\n",
      "\u001b[33mWARNING: You are using pip version 20.2; however, version 20.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting tensorflow==1.13.1\n",
      "  Using cached tensorflow-1.13.1-cp36-cp36m-manylinux1_x86_64.whl (92.5 MB)\n",
      "Collecting tensorboard<1.14.0,>=1.13.0\n",
      "  Using cached tensorboard-1.13.1-py3-none-any.whl (3.2 MB)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (3.13.0)\n",
      "Requirement already satisfied, skipping upgrade: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (0.3.3)\n",
      "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (1.0.8)\n",
      "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (1.1.2)\n",
      "Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (0.8.1)\n",
      "Requirement already satisfied, skipping upgrade: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (0.11.0)\n",
      "Collecting tensorflow-estimator<1.14.0rc0,>=1.13.0\n",
      "  Using cached tensorflow_estimator-1.13.0-py2.py3-none-any.whl (367 kB)\n",
      "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (1.33.2)\n",
      "Requirement already satisfied, skipping upgrade: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (0.35.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (1.16.4)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.3.3)\n",
      "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (1.0.1)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.13.1) (50.3.2)\n",
      "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.13.1) (2.10.0)\n",
      "Requirement already satisfied, skipping upgrade: mock>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow==1.13.1) (4.0.2)\n",
      "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (2.0.0)\n",
      "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.4.0)\n",
      "Installing collected packages: tensorboard, tensorflow-estimator, tensorflow\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.4.0\n",
      "    Uninstalling tensorboard-2.4.0:\n",
      "      Successfully uninstalled tensorboard-2.4.0\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.3.0\n",
      "    Uninstalling tensorflow-estimator-2.3.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.3.0\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.3.1\n",
      "    Uninstalling tensorflow-2.3.1:\n",
      "      Successfully uninstalled tensorflow-2.3.1\n",
      "\u001b[31mERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n",
      "\n",
      "We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n",
      "\n",
      "tensorflow-privacy 0.5.1 requires tensorflow-estimator>=2.3.0, but you'll have tensorflow-estimator 1.13.0 which is incompatible.\n",
      "tensorflow-federated 0.17.0 requires absl-py~=0.9.0, but you'll have absl-py 0.11.0 which is incompatible.\n",
      "tensorflow-federated 0.17.0 requires grpcio~=1.29.0, but you'll have grpcio 1.33.2 which is incompatible.\n",
      "tensorflow-federated 0.17.0 requires numpy~=1.18.4, but you'll have numpy 1.16.4 which is incompatible.\n",
      "tensorflow-federated 0.17.0 requires tensorflow~=2.3.0, but you'll have tensorflow 1.13.1 which is incompatible.\u001b[0m\n",
      "Successfully installed tensorboard-1.13.1 tensorflow-1.13.1 tensorflow-estimator-1.13.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 20.2; however, version 20.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already up-to-date: tensorboard==1.13.1 in /usr/local/lib/python3.6/dist-packages (1.13.1)\n",
      "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard==1.13.1) (3.3.3)\n",
      "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard==1.13.1) (1.0.1)\n",
      "Requirement already satisfied, skipping upgrade: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard==1.13.1) (0.11.0)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard==1.13.1) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard==1.13.1) (1.16.4)\n",
      "Requirement already satisfied, skipping upgrade: grpcio>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard==1.13.1) (1.33.2)\n",
      "Requirement already satisfied, skipping upgrade: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard==1.13.1) (0.35.1)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard==1.13.1) (3.13.0)\n",
      "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard==1.13.1) (2.0.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.0->tensorboard==1.13.1) (50.3.2)\n",
      "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard==1.13.1) (3.4.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.2; however, version 20.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting gast==0.4.0\n",
      "  Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Installing collected packages: gast\n",
      "  Attempting uninstall: gast\n",
      "    Found existing installation: gast 0.3.3\n",
      "    Uninstalling gast-0.3.3:\n",
      "      Successfully uninstalled gast-0.3.3\n",
      "\u001b[31mERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n",
      "\n",
      "We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n",
      "\n",
      "tensorflow-federated 0.17.0 requires absl-py~=0.9.0, but you'll have absl-py 0.11.0 which is incompatible.\n",
      "tensorflow-federated 0.17.0 requires grpcio~=1.29.0, but you'll have grpcio 1.33.2 which is incompatible.\n",
      "tensorflow-federated 0.17.0 requires numpy~=1.18.4, but you'll have numpy 1.16.4 which is incompatible.\n",
      "tensorflow-federated 0.17.0 requires tensorflow~=2.3.0, but you'll have tensorflow 1.13.1 which is incompatible.\u001b[0m\n",
      "Successfully installed gast-0.4.0\n",
      "\u001b[33mWARNING: You are using pip version 20.2; however, version 20.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already up-to-date: tensorflow-estimator==1.13.0 in /usr/local/lib/python3.6/dist-packages (1.13.0)\n",
      "Requirement already satisfied, skipping upgrade: mock>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-estimator==1.13.0) (4.0.2)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-estimator==1.13.0) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-estimator==1.13.0) (1.16.4)\n",
      "Requirement already satisfied, skipping upgrade: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-estimator==1.13.0) (0.11.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.2; however, version 20.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting cachetools==4.1.1\n",
      "  Using cached cachetools-4.1.1-py3-none-any.whl (10 kB)\n",
      "Installing collected packages: cachetools\n",
      "  Attempting uninstall: cachetools\n",
      "    Found existing installation: cachetools 3.1.1\n",
      "    Uninstalling cachetools-3.1.1:\n",
      "      Successfully uninstalled cachetools-3.1.1\n",
      "\u001b[31mERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n",
      "\n",
      "We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n",
      "\n",
      "tensorflow-federated 0.17.0 requires absl-py~=0.9.0, but you'll have absl-py 0.11.0 which is incompatible.\n",
      "tensorflow-federated 0.17.0 requires cachetools~=3.1.1, but you'll have cachetools 4.1.1 which is incompatible.\n",
      "tensorflow-federated 0.17.0 requires grpcio~=1.29.0, but you'll have grpcio 1.33.2 which is incompatible.\n",
      "tensorflow-federated 0.17.0 requires numpy~=1.18.4, but you'll have numpy 1.16.4 which is incompatible.\n",
      "tensorflow-federated 0.17.0 requires tensorflow~=2.3.0, but you'll have tensorflow 1.13.1 which is incompatible.\u001b[0m\n",
      "Successfully installed cachetools-4.1.1\n",
      "\u001b[33mWARNING: You are using pip version 20.2; however, version 20.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting attrs==19.1.0\n",
      "  Using cached attrs-19.1.0-py2.py3-none-any.whl (35 kB)\n",
      "Installing collected packages: attrs\n",
      "  Attempting uninstall: attrs\n",
      "    Found existing installation: attrs 19.3.0\n",
      "    Uninstalling attrs-19.3.0:\n",
      "      Successfully uninstalled attrs-19.3.0\n",
      "\u001b[31mERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n",
      "\n",
      "We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n",
      "\n",
      "tensorflow-federated 0.17.0 requires absl-py~=0.9.0, but you'll have absl-py 0.11.0 which is incompatible.\n",
      "tensorflow-federated 0.17.0 requires attrs~=19.3.0, but you'll have attrs 19.1.0 which is incompatible.\n",
      "tensorflow-federated 0.17.0 requires cachetools~=3.1.1, but you'll have cachetools 4.1.1 which is incompatible.\n",
      "tensorflow-federated 0.17.0 requires grpcio~=1.29.0, but you'll have grpcio 1.33.2 which is incompatible.\n",
      "tensorflow-federated 0.17.0 requires numpy~=1.18.4, but you'll have numpy 1.16.4 which is incompatible.\n",
      "tensorflow-federated 0.17.0 requires tensorflow~=2.3.0, but you'll have tensorflow 1.13.1 which is incompatible.\u001b[0m\n",
      "Successfully installed attrs-19.1.0\n",
      "\u001b[33mWARNING: You are using pip version 20.2; however, version 20.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade grpcio==1.33.2\n",
    "!pip install --upgrade numpy==1.16.4\n",
    "!pip install --upgrade absl-py==0.11.0\n",
    "!pip install --upgrade tensorflow==1.13.1\n",
    "!pip install --upgrade tensorboard==1.13.1\n",
    "!pip install --upgrade gast==0.4.0\n",
    "!pip install --upgrade tensorflow-estimator==1.13.0\n",
    "!pip install --upgrade cachetools==4.1.1\n",
    "!pip install --upgrade attrs==19.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tff-datasets-public/fed_cifar100.tar.bz2\n",
      "187613184/187610010 [==============================] - 28s 0us/step\n"
     ]
    }
   ],
   "source": [
    "federated_dataset = tff.simulation.datasets.cifar100.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "federated_train, federated_test = federated_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_from_ds(key, elem):\n",
    "    return elem[key]\n",
    "\n",
    "def preprocess_image(image):\n",
    "    return image / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_split(X, y, coarse_labels, test_fraction):\n",
    "    number_test_samples = int(len(y) * test_fraction)\n",
    "    classes, y_indices = np.unique(y, return_inverse=True)\n",
    "    class_counts = np.bincount(y_indices)\n",
    "    classes_sorted_by_count = np.flip(classes[np.argsort(class_counts)])\n",
    "    \n",
    "    test_indices = []\n",
    "    iteration = 0\n",
    "    while len(test_indices) < number_test_samples:\n",
    "        for elem in classes_sorted_by_count:\n",
    "            if class_counts[classes==elem] <= iteration:\n",
    "                continue\n",
    "            test_indices.append(np.argwhere(y_indices == np.argwhere(classes==elem)[0])[iteration].item())\n",
    "            if len(test_indices) >= number_test_samples:\n",
    "                break\n",
    "        iteration += 1\n",
    "        \n",
    "    X_test = np.array(X)[test_indices].tolist()\n",
    "    y_test = np.array(y)[test_indices].tolist()\n",
    "    coarse_labels_test = list(np.array(coarse_labels)[test_indices])\n",
    "    X_train = np.array(X)[~np.isin(np.arange(len(y)), test_indices)].tolist()\n",
    "    y_train = np.array(y)[~np.isin(np.arange(len(y)), test_indices)].tolist()\n",
    "    coarse_labels_train = list(np.array(coarse_labels)[~np.isin(np.arange(len(y)), test_indices)])\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test, coarse_labels_train, coarse_labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108: [ 0  0  0  2  0  0  1  0  0  0  0 23  0  0 16  0 29  0 29  0]\n",
      "121: [ 8  0  0  1  0  0  1  0  0  0  0  0 25  0 25  0  5 16  0 19]\n",
      "127: [ 0  0  0  7  0  6  0  0  0 20 18  0  0  0  5 14 20  0  6  4]\n",
      "148: [ 2  0 16 21  0  5 21  0 11  0  0  0  0  0 14  0  9  0  1  0]\n",
      "277: [ 0  7  0 36 12  0  0  0  0  8  0  0  0  0  0 36  0  1  0  0]\n",
      "320: [ 0  0  0  0  1 29  0  4  0  0 14  0  0  0  7 29  0  0 16  0]\n",
      "322: [21  0 16  0  0  0  0  0  0  5  0  2  0 17 21  0  3  0  0 15]\n",
      "371: [ 0 21  0  0  0  0 22  0  0  0 22  0  0  0  6 19  0  0  1  9]\n",
      "486: [ 0  0  0  0  0  1  3  0  0  0  4 46 46  0  0  0  0  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "train = {}\n",
    "test = {}\n",
    "cluster_ids = {}\n",
    "for client_id in federated_train.client_ids:\n",
    "    client_tf_dataset = federated_train.create_tf_dataset_for_client(client_id).shuffle(100, reshuffle_each_iteration=False)\n",
    "    X = list(client_tf_dataset.map(partial(extract_from_ds, 'image')).map(preprocess_image).as_numpy_iterator())\n",
    "    y = list(client_tf_dataset.map(partial(extract_from_ds, 'label')).as_numpy_iterator())\n",
    "    coarse_labels = list(client_tf_dataset.map(partial(extract_from_ds, 'coarse_label')).as_numpy_iterator())\n",
    "    \n",
    "    X_train, y_train, X_test, y_test, coarse_train, coarse_test = stratified_split(X, y, coarse_labels, 0.1)\n",
    "    # train_size = int(0.9 * len(y))\n",
    "    # X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=coarse_labels, test_size=0.1)\n",
    "    train[client_id] = {\n",
    "        'x': X_train,\n",
    "        'y': y_train\n",
    "    }\n",
    "    test[client_id] = {\n",
    "        'x': X_test,\n",
    "        'y': y_test\n",
    "    }\n",
    "    counts = np.bincount(coarse_labels, minlength=20)\n",
    "    max_elems = np.argwhere(counts == np.amax(counts)).flatten()\n",
    "    train_counts = np.bincount(coarse_train, minlength=20)\n",
    "    test_counts = np.bincount(coarse_test, minlength=20)\n",
    "    train_check = np.argwhere(train_counts == np.amax(train_counts)).flatten()\n",
    "    test_check = np.argwhere(test_counts == np.amax(test_counts)).flatten()\n",
    "    if len(max_elems) > 1:\n",
    "        print(f'{client_id}: {counts}')\n",
    "        cluster_id = int(np.random.choice(max_elems))\n",
    "    else:\n",
    "        cluster_id = int(max_elems[0])\n",
    "    if cluster_id not in train_check and cluster_id not in test_check:\n",
    "        print(f'{client_id}: cluster_id {cluster_id}, train_cluster_id {train_check}, test_cluster_id {test_check}')\n",
    "    cluster_ids[client_id] = cluster_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': 10, '1': 12, '10': 3, '100': 7, '101': 5, '102': 7, '103': 9, '104': 6, '105': 13, '106': 19, '107': 8, '108': 16, '109': 16, '11': 13, '110': 11, '111': 12, '112': 19, '113': 4, '114': 13, '115': 9, '116': 14, '117': 16, '118': 16, '119': 14, '12': 2, '120': 0, '121': 14, '122': 8, '123': 19, '124': 10, '125': 13, '126': 16, '127': 16, '128': 6, '129': 9, '13': 1, '130': 1, '131': 11, '132': 11, '133': 9, '134': 19, '135': 18, '136': 10, '137': 14, '138': 13, '139': 15, '14': 17, '140': 3, '141': 18, '142': 11, '143': 2, '144': 0, '145': 11, '146': 6, '147': 12, '148': 3, '149': 8, '15': 7, '150': 3, '151': 14, '152': 15, '153': 14, '154': 13, '155': 15, '156': 17, '157': 4, '158': 12, '159': 8, '16': 8, '160': 15, '161': 16, '162': 10, '163': 15, '164': 2, '165': 1, '166': 3, '167': 1, '168': 5, '169': 14, '17': 4, '170': 0, '171': 10, '172': 3, '173': 4, '174': 3, '175': 6, '176': 19, '177': 16, '178': 4, '179': 17, '18': 15, '180': 13, '181': 1, '182': 5, '183': 3, '184': 8, '185': 17, '186': 19, '187': 1, '188': 13, '189': 19, '19': 4, '190': 3, '191': 19, '192': 3, '193': 4, '194': 10, '195': 18, '196': 14, '197': 1, '198': 5, '199': 10, '2': 18, '20': 10, '200': 0, '201': 0, '202': 2, '203': 15, '204': 6, '205': 6, '206': 16, '207': 6, '208': 13, '209': 9, '21': 0, '210': 15, '211': 0, '212': 1, '213': 13, '214': 5, '215': 15, '216': 3, '217': 6, '218': 4, '219': 7, '22': 16, '220': 6, '221': 1, '222': 14, '223': 9, '224': 1, '225': 4, '226': 9, '227': 19, '228': 15, '229': 13, '23': 14, '230': 11, '231': 3, '232': 5, '233': 1, '234': 11, '235': 18, '236': 10, '237': 5, '238': 19, '239': 13, '24': 13, '240': 3, '241': 0, '242': 15, '243': 7, '244': 9, '245': 13, '246': 10, '247': 7, '248': 0, '249': 12, '25': 9, '250': 6, '251': 7, '252': 2, '253': 7, '254': 19, '255': 4, '256': 16, '257': 5, '258': 3, '259': 13, '26': 1, '260': 0, '261': 10, '262': 9, '263': 6, '264': 15, '265': 6, '266': 11, '267': 11, '268': 1, '269': 14, '27': 3, '270': 19, '271': 14, '272': 9, '273': 4, '274': 1, '275': 14, '276': 19, '277': 3, '278': 2, '279': 17, '28': 6, '280': 18, '281': 6, '282': 4, '283': 16, '284': 14, '285': 4, '286': 4, '287': 11, '288': 6, '289': 15, '29': 0, '290': 11, '291': 13, '292': 2, '293': 5, '294': 17, '295': 17, '296': 17, '297': 9, '298': 9, '299': 8, '3': 16, '30': 2, '300': 19, '301': 11, '302': 18, '303': 17, '304': 16, '305': 12, '306': 2, '307': 13, '308': 12, '309': 0, '31': 15, '310': 12, '311': 4, '312': 16, '313': 4, '314': 18, '315': 3, '316': 14, '317': 3, '318': 15, '319': 13, '32': 14, '320': 5, '321': 9, '322': 14, '323': 0, '324': 9, '325': 0, '326': 6, '327': 5, '328': 17, '329': 10, '33': 18, '330': 9, '331': 14, '332': 0, '333': 16, '334': 11, '335': 11, '336': 8, '337': 9, '338': 2, '339': 18, '34': 1, '340': 4, '341': 5, '342': 12, '343': 1, '344': 4, '345': 17, '346': 14, '347': 7, '348': 17, '349': 9, '35': 6, '350': 7, '351': 15, '352': 17, '353': 11, '354': 4, '355': 18, '356': 4, '357': 15, '358': 0, '359': 3, '36': 0, '360': 1, '361': 12, '362': 3, '363': 5, '364': 17, '365': 1, '366': 19, '367': 16, '368': 16, '369': 10, '37': 0, '370': 12, '371': 10, '372': 4, '373': 14, '374': 0, '375': 8, '376': 14, '377': 9, '378': 4, '379': 6, '38': 13, '380': 10, '381': 13, '382': 7, '383': 3, '384': 10, '385': 6, '386': 5, '387': 18, '388': 6, '389': 8, '39': 0, '390': 9, '391': 16, '392': 17, '393': 12, '394': 14, '395': 12, '396': 12, '397': 17, '398': 8, '399': 9, '4': 2, '40': 13, '400': 17, '401': 0, '402': 1, '403': 19, '404': 17, '405': 7, '406': 15, '407': 19, '408': 3, '409': 0, '41': 2, '410': 3, '411': 11, '412': 4, '413': 5, '414': 11, '415': 12, '416': 17, '417': 9, '418': 0, '419': 1, '42': 13, '420': 10, '421': 4, '422': 5, '423': 17, '424': 17, '425': 2, '426': 10, '427': 5, '428': 2, '429': 6, '43': 19, '430': 8, '431': 9, '432': 17, '433': 10, '434': 14, '435': 4, '436': 12, '437': 19, '438': 11, '439': 8, '44': 13, '440': 4, '441': 1, '442': 6, '443': 2, '444': 11, '445': 15, '446': 7, '447': 8, '448': 14, '449': 19, '45': 17, '450': 2, '451': 7, '452': 7, '453': 10, '454': 3, '455': 18, '456': 10, '457': 19, '458': 7, '459': 9, '46': 14, '460': 1, '461': 2, '462': 1, '463': 8, '464': 18, '465': 5, '466': 1, '467': 19, '468': 19, '469': 3, '47': 0, '470': 5, '471': 15, '472': 19, '473': 2, '474': 15, '475': 11, '476': 7, '477': 8, '478': 18, '479': 6, '48': 1, '480': 7, '481': 2, '482': 5, '483': 5, '484': 11, '485': 2, '486': 11, '487': 19, '488': 8, '489': 7, '49': 15, '490': 2, '491': 2, '492': 5, '493': 8, '494': 7, '495': 8, '496': 8, '497': 5, '498': 5, '499': 5, '5': 1, '50': 12, '51': 19, '52': 17, '53': 7, '54': 17, '55': 1, '56': 16, '57': 0, '58': 1, '59': 12, '6': 10, '60': 9, '61': 11, '62': 14, '63': 16, '64': 19, '65': 16, '66': 4, '67': 14, '68': 13, '69': 1, '7': 4, '70': 6, '71': 12, '72': 1, '73': 3, '74': 18, '75': 7, '76': 13, '77': 2, '78': 1, '79': 8, '8': 4, '80': 13, '81': 11, '82': 12, '83': 2, '84': 2, '85': 15, '86': 17, '87': 9, '88': 11, '89': 15, '9': 5, '90': 18, '91': 6, '92': 0, '93': 16, '94': 7, '95': 6, '96': 15, '97': 15, '98': 9, '99': 12}\n",
      "['0', '1', '10', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '11', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '12', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '13', '130', '131', '132', '133', '134', '135', '136', '137', '138', '139', '14', '140', '141', '142', '143', '144', '145', '146', '147', '148', '149', '15', '150', '151', '152', '153', '154', '155', '156', '157', '158', '159', '16', '160', '161', '162', '163', '164', '165', '166', '167', '168', '169', '17', '170', '171', '172', '173', '174', '175', '176', '177', '178', '179', '18', '180', '181', '182', '183', '184', '185', '186', '187', '188', '189', '19', '190', '191', '192', '193', '194', '195', '196', '197', '198', '199', '2', '20', '200', '201', '202', '203', '204', '205', '206', '207', '208', '209', '21', '210', '211', '212', '213', '214', '215', '216', '217', '218', '219', '22', '220', '221', '222', '223', '224', '225', '226', '227', '228', '229', '23', '230', '231', '232', '233', '234', '235', '236', '237', '238', '239', '24', '240', '241', '242', '243', '244', '245', '246', '247', '248', '249', '25', '250', '251', '252', '253', '254', '255', '256', '257', '258', '259', '26', '260', '261', '262', '263', '264', '265', '266', '267', '268', '269', '27', '270', '271', '272', '273', '274', '275', '276', '277', '278', '279', '28', '280', '281', '282', '283', '284', '285', '286', '287', '288', '289', '29', '290', '291', '292', '293', '294', '295', '296', '297', '298', '299', '3', '30', '300', '301', '302', '303', '304', '305', '306', '307', '308', '309', '31', '310', '311', '312', '313', '314', '315', '316', '317', '318', '319', '32', '320', '321', '322', '323', '324', '325', '326', '327', '328', '329', '33', '330', '331', '332', '333', '334', '335', '336', '337', '338', '339', '34', '340', '341', '342', '343', '344', '345', '346', '347', '348', '349', '35', '350', '351', '352', '353', '354', '355', '356', '357', '358', '359', '36', '360', '361', '362', '363', '364', '365', '366', '367', '368', '369', '37', '370', '371', '372', '373', '374', '375', '376', '377', '378', '379', '38', '380', '381', '382', '383', '384', '385', '386', '387', '388', '389', '39', '390', '391', '392', '393', '394', '395', '396', '397', '398', '399', '4', '40', '400', '401', '402', '403', '404', '405', '406', '407', '408', '409', '41', '410', '411', '412', '413', '414', '415', '416', '417', '418', '419', '42', '420', '421', '422', '423', '424', '425', '426', '427', '428', '429', '43', '430', '431', '432', '433', '434', '435', '436', '437', '438', '439', '44', '440', '441', '442', '443', '444', '445', '446', '447', '448', '449', '45', '450', '451', '452', '453', '454', '455', '456', '457', '458', '459', '46', '460', '461', '462', '463', '464', '465', '466', '467', '468', '469', '47', '470', '471', '472', '473', '474', '475', '476', '477', '478', '479', '48', '480', '481', '482', '483', '484', '485', '486', '487', '488', '489', '49', '490', '491', '492', '493', '494', '495', '496', '497', '498', '499', '5', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '6', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '7', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '8', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '9', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99']\n"
     ]
    }
   ],
   "source": [
    "#print(np.unique(list(cluster_ids.keys())))\n",
    "print(cluster_ids)\n",
    "print(list(train.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_output = {\n",
    "    'user_data': train,\n",
    "    'cluster_ids': list(cluster_ids.values()),\n",
    "    'users': list(train.keys())\n",
    "}\n",
    "test_output = {\n",
    "    'user_data': test,\n",
    "    'cluster_ids': list(cluster_ids.values()),\n",
    "    'users': list(train.keys())\n",
    "}\n",
    "\n",
    "with open('../../.././data/cifar100/train/data.json', 'w') as file: \n",
    "    json.dump(train_output, file)\n",
    "with open('../../.././data/cifar100/test/data.json', 'w') as file: \n",
    "    json.dump(test_output, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unused computation of test\n",
    "test = {}\n",
    "test_cluster_ids = {}\n",
    "for client_id in federated_test.client_ids:\n",
    "    client_tf_dataset = federated_test.create_tf_dataset_for_client(client_id)\n",
    "    test[client_id] = {\n",
    "        'x': list(client_tf_dataset.map(partial(extract_from_ds, 'image')).map(preprocess_image).as_numpy_iterator()),\n",
    "        'y': list(client_tf_dataset.map(partial(extract_from_ds, 'label')).as_numpy_iterator())\n",
    "    }\n",
    "    coarse_labels = list(client_tf_dataset.map(partial(extract_from_ds, 'coarse_label')).as_numpy_iterator())\n",
    "    counts = np.bincount(coarse_labels, minlength=20)\n",
    "    max_elems = np.argwhere(counts == np.amax(counts)).flatten()\n",
    "    if len(max_elems) > 1:\n",
    "        print(counts)\n",
    "        test_cluster_id = np.random.choice(max_elems)\n",
    "    else:\n",
    "        test_cluster_id = max_elems[0]\n",
    "    test_cluster_ids[client_id] = test_cluster_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "# Number of clients in train/test\n",
    "print(len(train.keys()))\n",
    "print(len(test.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27 31 25 26 29 25 27 23 21 27 21 24 23 26 25 27 23 26 17 27]\n",
      "[6 6 6 6 6 5 4 4 3 5 5 5 4 6 8 3 4 4 5 5]\n"
     ]
    }
   ],
   "source": [
    "# Number of Cluster clients in train/test\n",
    "print(np.bincount(list(cluster_ids.values()), minlength=20))\n",
    "print(np.bincount(list(test_cluster_ids.values()), minlength=20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90.0\n",
      "10.0\n"
     ]
    }
   ],
   "source": [
    "# Average amount of local data in train/test\n",
    "print(np.mean([len(elem['x']) for elem in train.values()]))\n",
    "print(np.mean([len(elem['x']) for elem in test.values()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i in np.argwhere(np.array(test['0']['y']) == 93).flatten().tolist():\n",
    "    print(test['0']['y'][i])\n",
    "    plt.imshow(test['0']['x'][i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23 27 29 33 34 49 60 63 71 93]\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(test['0']['y']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0 15 21 23 27 29 33 34 38 44 45 49 51 60 63 64 71 75 77 88 93 99]\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(train['0']['y']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
